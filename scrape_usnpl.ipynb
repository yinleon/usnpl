{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 2018-02-27 14:50:36.395425\n",
      "By leonyin\n",
      "Using Python 3.6.1\n",
      "On Darwin-17.4.0-x86_64-i386-64bit\n"
     ]
    }
   ],
   "source": [
    "runtime_meta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USNPL\n",
    "A scraper for the <a hef=\"http://www.usnpl.com/canews.php\">usnpl</a> site for newspapers, magazines, and college papers.\n",
    "\n",
    "### The output has\n",
    "Geography - The state of the media source.<br>\n",
    "Name - The name of the media source.<br>\n",
    "Facebook - The URL for the Facebook account.<br>\n",
    "Twitter_Name - The Tweet screen name for the Twitter account.<br>\n",
    "Twitter_ID - The Tweet ID for the Twitter Account.<br>\n",
    "Website - The URL for the media source<br>\n",
    "Medium - What format is the media source?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = '''ak\t  al\t  ar\t  az\t  ca\t  co\t  ct\t  dc\t  de\t  fl\t  ga\t  hi\t  ia\t  id\t  il\t  in\t  ks   ky\t  la\t  ma\t  md\t  me\t  mi\t  mn\t  mo\t  ms\t  mt\t  nc\t  nd\t  ne\t  nh\t  nj\t  nm\t  nv\t  ny\t  oh\t  ok\t  or\t  pa\t  ri\t  sc\t  sd\t  tn\t  tx\t  ut\t  va\t  vt\t  wa\t  wi\t  wv\t  wy\t'''\n",
    "states = [s.strip() for s in states.split('  ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_row(soup):\n",
    "    city = soup.find('b').text\n",
    "    name = soup.find('a').text\n",
    "    web = soup.find('a').get('href')\n",
    "    \n",
    "    fb = soup.find('a', text='F')\n",
    "    if fb:\n",
    "        fb= fb.get('href')\n",
    "    tw = soup.find('a', text='T')\n",
    "    if tw:\n",
    "        tw=tw.get('href').replace('http://www.twitter.com/', '')\n",
    "    \n",
    "    return {\n",
    "        'Facebook' : fb,\n",
    "        'Twitter_Name' : tw,\n",
    "        'Name' : name,\n",
    "        'Website' : web\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites = []\n",
    "for state in states:\n",
    "    url = 'http://www.usnpl.com/{}news.php'.format(state)\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'lxml')\n",
    "    \n",
    "    data_possibilities = soup.find_all('div' ,{\"id\" : 'data_box'})\n",
    "    for i, raw_table in enumerate(data_possibilities[1:]):\n",
    "        j = 1 if i == 0 else 0\n",
    "        medium = raw_table.find('h3').text\n",
    "        if medium == 'Newspapers':\n",
    "            data_table = str(raw_table).split('<br/><br/>\\n</div>\\n')[j]\n",
    "            entries_to_parse = data_table.rstrip('</div>').split('\\n<br/>\\n')\n",
    "        elif medium in ['Magazines', 'College Newspapers']:\n",
    "            data_table = str(raw_table).split('<title>Untitled Document</title>')[1]\n",
    "            entries_to_parse = data_table.rstrip('</div>').split('\\n<br/>\\n')\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "        for row in tqdm(entries_to_parse):\n",
    "            row = row.strip('\\r').strip('\\n')\n",
    "            if row:\n",
    "                entry = parse_row(BeautifulSoup(row, 'lxml'))\n",
    "                entry['Geography'] = state.upper()\n",
    "                entry['Medium'] = medium\n",
    "                sites.append(entry)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facebook</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Medium</th>\n",
       "      <th>Name</th>\n",
       "      <th>Twitter_Name</th>\n",
       "      <th>Website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.facebook.com/akdispatch</td>\n",
       "      <td>AK</td>\n",
       "      <td>Newspapers</td>\n",
       "      <td>Alaska Dispatch News</td>\n",
       "      <td>adndotcom</td>\n",
       "      <td>http://www.adn.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.facebook.com/AlaskaJournal</td>\n",
       "      <td>AK</td>\n",
       "      <td>Newspapers</td>\n",
       "      <td>Alaska Journal of Commerce</td>\n",
       "      <td>alaskajournal</td>\n",
       "      <td>http://www.alaskajournal.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.facebook.com/anchoragepress</td>\n",
       "      <td>AK</td>\n",
       "      <td>Newspapers</td>\n",
       "      <td>Anchorage Press</td>\n",
       "      <td>anchoragepress</td>\n",
       "      <td>http://www.anchoragepress.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.facebook.com/PetroleumNews</td>\n",
       "      <td>AK</td>\n",
       "      <td>Newspapers</td>\n",
       "      <td>Petroleum News</td>\n",
       "      <td>None</td>\n",
       "      <td>http://www.petroleumnews.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.facebook.com/deltadiscovery</td>\n",
       "      <td>AK</td>\n",
       "      <td>Newspapers</td>\n",
       "      <td>Delta Discovery</td>\n",
       "      <td>None</td>\n",
       "      <td>http://www.deltadiscovery.com/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Facebook Geography      Medium  \\\n",
       "0      https://www.facebook.com/akdispatch        AK  Newspapers   \n",
       "1   https://www.facebook.com/AlaskaJournal        AK  Newspapers   \n",
       "2  https://www.facebook.com/anchoragepress        AK  Newspapers   \n",
       "3   https://www.facebook.com/PetroleumNews        AK  Newspapers   \n",
       "4  https://www.facebook.com/deltadiscovery        AK  Newspapers   \n",
       "\n",
       "                         Name    Twitter_Name                         Website  \n",
       "0        Alaska Dispatch News       adndotcom             http://www.adn.com/  \n",
       "1  Alaska Journal of Commerce   alaskajournal   http://www.alaskajournal.com/  \n",
       "2            Anchorage Press   anchoragepress  http://www.anchoragepress.com/  \n",
       "3              Petroleum News            None   http://www.petroleumnews.com/  \n",
       "4             Delta Discovery            None  http://www.deltadiscovery.com/  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('data/usnpl_newspapers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Twitter User IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill these in!\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_key = ''\n",
    "access_secret = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth,\n",
    "                 wait_on_rate_limit=True,\n",
    "                 wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_names = df[~df['Twitter_Name'].isnull()]['Twitter_Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user = api.get_user(twitter_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contributors_enabled': False,\n",
       " 'created_at': 'Thu Dec 20 22:51:16 +0000 2012',\n",
       " 'default_profile': False,\n",
       " 'default_profile_image': False,\n",
       " 'description': 'We manage and conserve more than 800 species of wildlife statewide. | Conserving Wildlife~Serving People | Follows and retweets do not imply endorsement.',\n",
       " 'entities': {'description': {'urls': []},\n",
       "  'url': {'urls': [{'display_url': 'wgfd.wyo.gov',\n",
       "     'expanded_url': 'http://wgfd.wyo.gov',\n",
       "     'indices': [0, 22],\n",
       "     'url': 'http://t.co/ru1Gs8tBEq'}]}},\n",
       " 'favourites_count': 298,\n",
       " 'follow_request_sent': False,\n",
       " 'followers_count': 3788,\n",
       " 'following': False,\n",
       " 'friends_count': 676,\n",
       " 'geo_enabled': False,\n",
       " 'has_extended_profile': False,\n",
       " 'id': 1025185082,\n",
       " 'id_str': '1025185082',\n",
       " 'is_translation_enabled': False,\n",
       " 'is_translator': False,\n",
       " 'lang': 'en',\n",
       " 'listed_count': 65,\n",
       " 'location': 'Wyoming - USA',\n",
       " 'name': 'Wyoming Game & Fish',\n",
       " 'notifications': False,\n",
       " 'profile_background_color': '5D7388',\n",
       " 'profile_background_image_url': 'http://pbs.twimg.com/profile_background_images/540188072147570689/af7ramu5.jpeg',\n",
       " 'profile_background_image_url_https': 'https://pbs.twimg.com/profile_background_images/540188072147570689/af7ramu5.jpeg',\n",
       " 'profile_background_tile': False,\n",
       " 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1025185082/1466458607',\n",
       " 'profile_image_url': 'http://pbs.twimg.com/profile_images/826446705792913410/NJ9ULI2W_normal.jpg',\n",
       " 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/826446705792913410/NJ9ULI2W_normal.jpg',\n",
       " 'profile_link_color': '5D7388',\n",
       " 'profile_location': None,\n",
       " 'profile_sidebar_border_color': '000000',\n",
       " 'profile_sidebar_fill_color': 'DDEEF6',\n",
       " 'profile_text_color': '333333',\n",
       " 'profile_use_background_image': True,\n",
       " 'protected': False,\n",
       " 'screen_name': 'WGFD',\n",
       " 'status': {'contributors': None,\n",
       "  'coordinates': None,\n",
       "  'created_at': 'Mon Feb 19 01:00:01 +0000 2018',\n",
       "  'entities': {'hashtags': [],\n",
       "   'symbols': [],\n",
       "   'urls': [{'display_url': 'twitter.com/i/web/status/9…',\n",
       "     'expanded_url': 'https://twitter.com/i/web/status/965390481667469312',\n",
       "     'indices': [117, 140],\n",
       "     'url': 'https://t.co/GMm5BSVAxw'}],\n",
       "   'user_mentions': []},\n",
       "  'favorite_count': 8,\n",
       "  'favorited': False,\n",
       "  'geo': None,\n",
       "  'id': 965390481667469312,\n",
       "  'id_str': '965390481667469312',\n",
       "  'in_reply_to_screen_name': None,\n",
       "  'in_reply_to_status_id': None,\n",
       "  'in_reply_to_status_id_str': None,\n",
       "  'in_reply_to_user_id': None,\n",
       "  'in_reply_to_user_id_str': None,\n",
       "  'is_quote_status': False,\n",
       "  'lang': 'en',\n",
       "  'place': None,\n",
       "  'possibly_sensitive': False,\n",
       "  'retweet_count': 0,\n",
       "  'retweeted': False,\n",
       "  'source': '<a href=\"https://ads-api.twitter.com\" rel=\"nofollow\">Twitter Ads Composer</a>',\n",
       "  'text': \"Applying for a hunting license soon? Consider purchasing a few Super Tag Raffle tickets while you're at it. One tic… https://t.co/GMm5BSVAxw\",\n",
       "  'truncated': True},\n",
       " 'statuses_count': 1794,\n",
       " 'time_zone': 'Arizona',\n",
       " 'translator_type': 'none',\n",
       " 'url': 'http://t.co/ru1Gs8tBEq',\n",
       " 'utc_offset': -25200,\n",
       " 'verified': False}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user._json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tweepy import TweepError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599f951ccf2a4b45afa66a231dd02572"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 85\n",
      "Rate limit reached. Sleeping for: 500\n",
      "Rate limit reached. Sleeping for: 487\n",
      "Rate limit reached. Sleeping for: 539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_ids = []\n",
    "for screen_name in tqdm(twitter_names):\n",
    "    try:\n",
    "        user = api.get_user(screen_name=screen_name)\n",
    "        user_id = user.id\n",
    "    except TweepError:\n",
    "        user_id = None\n",
    "        pass\n",
    "    user_ids.append({\n",
    "        'Twitter_ID' : user_id,\n",
    "        'Twitter_Name' : screen_name\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_users = pd.DataFrame(user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_users['Twitter_ID'] = df_users['Twitter_ID'].astype(str).str.replace('.0','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_users.to_csv('data/twitter_uers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merge = df.merge(df_users, on='Twitter_Name', how='left')[['Name', 'Medium', 'Website', 'Facebook', 'Twitter_Name','Twitter_ID', 'Geography']]\n",
    "df_merge.to_csv('data/usnpl_newspapers_twitter_ids.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Medium</th>\n",
       "      <th>Website</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>Twitter_Name</th>\n",
       "      <th>Twitter_ID</th>\n",
       "      <th>Geography</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alaska Dispatch News</td>\n",
       "      <td>Newspapers</td>\n",
       "      <td>http://www.adn.com/</td>\n",
       "      <td>https://www.facebook.com/akdispatch</td>\n",
       "      <td>adndotcom</td>\n",
       "      <td>158225</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska Journal of Commerce</td>\n",
       "      <td>Newspapers</td>\n",
       "      <td>http://www.alaskajournal.com/</td>\n",
       "      <td>https://www.facebook.com/AlaskaJournal</td>\n",
       "      <td>alaskajournal</td>\n",
       "      <td>341639834</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anchorage Press</td>\n",
       "      <td>Newspapers</td>\n",
       "      <td>http://www.anchoragepress.com/</td>\n",
       "      <td>https://www.facebook.com/anchoragepress</td>\n",
       "      <td>anchoragepress</td>\n",
       "      <td>17761344</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Petroleum News</td>\n",
       "      <td>Newspapers</td>\n",
       "      <td>http://www.petroleumnews.com/</td>\n",
       "      <td>https://www.facebook.com/PetroleumNews</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delta Discovery</td>\n",
       "      <td>Newspapers</td>\n",
       "      <td>http://www.deltadiscovery.com/</td>\n",
       "      <td>https://www.facebook.com/deltadiscovery</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name      Medium                         Website  \\\n",
       "0        Alaska Dispatch News  Newspapers             http://www.adn.com/   \n",
       "1  Alaska Journal of Commerce  Newspapers   http://www.alaskajournal.com/   \n",
       "2            Anchorage Press   Newspapers  http://www.anchoragepress.com/   \n",
       "3              Petroleum News  Newspapers   http://www.petroleumnews.com/   \n",
       "4             Delta Discovery  Newspapers  http://www.deltadiscovery.com/   \n",
       "\n",
       "                                  Facebook    Twitter_Name Twitter_ID  \\\n",
       "0      https://www.facebook.com/akdispatch       adndotcom     158225   \n",
       "1   https://www.facebook.com/AlaskaJournal   alaskajournal  341639834   \n",
       "2  https://www.facebook.com/anchoragepress  anchoragepress   17761344   \n",
       "3   https://www.facebook.com/PetroleumNews            None        NaN   \n",
       "4  https://www.facebook.com/deltadiscovery            None        NaN   \n",
       "\n",
       "  Geography  \n",
       "0        AK  \n",
       "1        AK  \n",
       "2        AK  \n",
       "3        AK  \n",
       "4        AK  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
